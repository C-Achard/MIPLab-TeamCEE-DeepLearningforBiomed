{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: C:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed\\DATA\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         imports\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from training import *\n",
    "from models import *\n",
    "from utils import * \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "## Data path ##\n",
    "DATA_PATH = (Path.cwd().parent / \"DATA\").resolve() # TODO : adapt to server\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "DATA_PATH = str(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         hyperparameters\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "config = {\n",
    "    # general\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "\n",
    "    # model\n",
    "    \"d_model_input\": 400,\n",
    "    \"d_model_intermediate\": 512,\n",
    "    \"d_model_task_output\": 8,\n",
    "    \"d_model_fingerprint_output\": None, # needs to be determined from data\n",
    "    \"dropout\" : 0.1,\n",
    "    \"attention_dropout\" : 0.1,\n",
    "    \"num_heads\": 4,\n",
    "    \"num_layers\": 0, # TBA?\n",
    "\n",
    "    # optimizer\n",
    "    \"lambda_si\": 0.6,\n",
    "    \"lambda_td\": 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         subject ID list\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "IDs = [100307,  117122,  131722,  153025,  211720,\n",
    "100408,  118528,  133019,  154734,  212318,      \n",
    "101107,  118730,  133928,  156637,  214423,        \n",
    "101309,  118932,  135225,  159340,  221319,       \n",
    "101915,  120111,  135932,  160123,  239944 ,      \n",
    "103111,  122317,  136833,  161731,  245333,        \n",
    "103414,  122620,  138534,  162733,  280739,        \n",
    "103818, 123117,  139637,  163129,  298051,        \n",
    "105014,  123925,  140925,  176542,  366446,        \n",
    "105115,  124422,  144832,  178950,  397760,        \n",
    "106016,  125525,  146432,  188347,  414229,        \n",
    "108828,  126325,  147737,  189450,  499566,\n",
    "110411,  127630,  148335,  190031,  654754,\n",
    "111312,  127933,  148840,  192540,  672756,\n",
    "111716,  128127,  149337,  196750,  751348,\n",
    "113619,  128632,  149539,  198451,  756055,\n",
    "113922,  129028,  149741,  199655,  792564,\n",
    "114419,  130013,  151223,  201111,  856766,\n",
    "115320,  130316,  151526,  208226,  857263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>mat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.21854491103466994, 0.07509374392964863, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST2</td>\n",
       "      <td>[[0.2509722712619662, 0.06429771271159306, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100307</td>\n",
       "      <td>EMOTION</td>\n",
       "      <td>[[0.27626702525883573, 0.03827488524289221, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100307</td>\n",
       "      <td>GAMBLING</td>\n",
       "      <td>[[0.2356709594115424, 0.03883497545044236, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100307</td>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>[[0.2317390561241142, 0.06537822245634475, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100307</td>\n",
       "      <td>MOTOR</td>\n",
       "      <td>[[0.2141270371266362, 0.040754342863046, 0.084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100307</td>\n",
       "      <td>RELATIONAL</td>\n",
       "      <td>[[0.2709434948110919, 0.08915439190003989, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100307</td>\n",
       "      <td>SOCIAL</td>\n",
       "      <td>[[0.27075755129825896, 0.07942572217389814, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100307</td>\n",
       "      <td>WM</td>\n",
       "      <td>[[0.28122430896568573, 0.12358947079320645, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100408</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.31926332845816463, 0.18973934066088882, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id     task_id                                                mat\n",
       "0     100307       REST1  [[0.21854491103466994, 0.07509374392964863, 0....\n",
       "1     100307       REST2  [[0.2509722712619662, 0.06429771271159306, 0.1...\n",
       "2     100307     EMOTION  [[0.27626702525883573, 0.03827488524289221, 0....\n",
       "3     100307    GAMBLING  [[0.2356709594115424, 0.03883497545044236, 0.1...\n",
       "4     100307    LANGUAGE  [[0.2317390561241142, 0.06537822245634475, 0.0...\n",
       "5     100307       MOTOR  [[0.2141270371266362, 0.040754342863046, 0.084...\n",
       "6     100307  RELATIONAL  [[0.2709434948110919, 0.08915439190003989, 0.1...\n",
       "7     100307      SOCIAL  [[0.27075755129825896, 0.07942572217389814, 0....\n",
       "8     100307          WM  [[0.28122430896568573, 0.12358947079320645, 0....\n",
       "9     100408       REST1  [[0.31926332845816463, 0.18973934066088882, 0...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         joining train and test dataframes from all subjects\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# data_dict_train, data_dict_test = get_dict_raw_data(DATA_PATH, IDs[0:3])\n",
    "data_df_train, data_df_test = get_df_raw_data(DATA_PATH, [IDs[0], IDs[5], IDs[10]])\n",
    "display(data_df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 3\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJECTS = len(data_df_train[\"subject_id\"].unique())\n",
    "print(f\"Number of subjects: {NUM_SUBJECTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         label encoding\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# one hot encoding\n",
    "\n",
    "# enc_labels = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc_tasks = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# enc_labels.fit(data_dict_train[\"subject_id\"].to_numpy().reshape(-1, 1))\n",
    "# enc_tasks.fit(data_dict_train[\"task_id\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# enc_train_label_encodings = enc_labels.transform(data_dict_train[\"subject_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "# enc_train_task_encodings = enc_tasks.transform(data_dict_train[\"task_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# enc_test_label_encodings = enc_labels.transform(data_dict_test[\"subject_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "# enc_test_task_encodings = enc_tasks.transform(data_dict_test[\"task_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# data_dict_train[\"enc_label_id\"] = enc_train_label_encodings.tolist()\n",
    "# data_dict_train[\"enc_task_id\"] = enc_train_task_encodings.tolist()\n",
    "\n",
    "# data_dict_test[\"enc_label_id\"] = enc_test_label_encodings.tolist()\n",
    "# data_dict_test[\"enc_task_id\"] = enc_test_task_encodings.tolist()\n",
    "\n",
    "# label encoding\n",
    "enc_labels = LabelEncoder()\n",
    "enc_tasks = LabelEncoder()\n",
    "\n",
    "enc_labels.fit(data_df_train[\"subject_id\"].tolist())\n",
    "enc_tasks.fit(data_df_train[\"task_id\"].tolist())\n",
    "\n",
    "enc_train_label_encodings = enc_labels.transform(data_df_train[\"subject_id\"].tolist())\n",
    "enc_train_task_encodings = enc_tasks.transform(data_df_train[\"task_id\"].tolist())\n",
    "\n",
    "enc_test_label_encodings = enc_labels.transform(data_df_test[\"subject_id\"].tolist())\n",
    "enc_test_task_encodings = enc_tasks.transform(data_df_test[\"task_id\"].tolist())\n",
    "\n",
    "data_df_train[\"enc_label_id\"] = enc_train_label_encodings\n",
    "data_df_train[\"enc_task_id\"] = enc_train_task_encodings\n",
    "data_df_test[\"enc_label_id\"] = enc_test_label_encodings\n",
    "data_df_test[\"enc_task_id\"] = enc_test_task_encodings\n",
    "\n",
    "#enc.inverse_transform() to reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>mat</th>\n",
       "      <th>enc_label_id</th>\n",
       "      <th>enc_task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.21854491103466994, 0.07509374392964863, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST2</td>\n",
       "      <td>[[0.2509722712619662, 0.06429771271159306, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100307</td>\n",
       "      <td>EMOTION</td>\n",
       "      <td>[[0.27626702525883573, 0.03827488524289221, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100307</td>\n",
       "      <td>GAMBLING</td>\n",
       "      <td>[[0.2356709594115424, 0.03883497545044236, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100307</td>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>[[0.2317390561241142, 0.06537822245634475, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100307</td>\n",
       "      <td>MOTOR</td>\n",
       "      <td>[[0.2141270371266362, 0.040754342863046, 0.084...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100307</td>\n",
       "      <td>RELATIONAL</td>\n",
       "      <td>[[0.2709434948110919, 0.08915439190003989, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100307</td>\n",
       "      <td>SOCIAL</td>\n",
       "      <td>[[0.27075755129825896, 0.07942572217389814, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100307</td>\n",
       "      <td>WM</td>\n",
       "      <td>[[0.28122430896568573, 0.12358947079320645, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100408</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.31926332845816463, 0.18973934066088882, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id     task_id                                                mat  \\\n",
       "0     100307       REST1  [[0.21854491103466994, 0.07509374392964863, 0....   \n",
       "1     100307       REST2  [[0.2509722712619662, 0.06429771271159306, 0.1...   \n",
       "2     100307     EMOTION  [[0.27626702525883573, 0.03827488524289221, 0....   \n",
       "3     100307    GAMBLING  [[0.2356709594115424, 0.03883497545044236, 0.1...   \n",
       "4     100307    LANGUAGE  [[0.2317390561241142, 0.06537822245634475, 0.0...   \n",
       "5     100307       MOTOR  [[0.2141270371266362, 0.040754342863046, 0.084...   \n",
       "6     100307  RELATIONAL  [[0.2709434948110919, 0.08915439190003989, 0.1...   \n",
       "7     100307      SOCIAL  [[0.27075755129825896, 0.07942572217389814, 0....   \n",
       "8     100307          WM  [[0.28122430896568573, 0.12358947079320645, 0....   \n",
       "9     100408       REST1  [[0.31926332845816463, 0.18973934066088882, 0....   \n",
       "\n",
       "   enc_label_id  enc_task_id  \n",
       "0             0            5  \n",
       "1             0            6  \n",
       "2             0            0  \n",
       "3             0            1  \n",
       "4             0            2  \n",
       "5             0            3  \n",
       "6             0            4  \n",
       "7             0            7  \n",
       "8             0            8  \n",
       "9             1            5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         initializing dataloader objects\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(\n",
    "        np.array(data_df_train[\"mat\"].tolist()).astype(np.float32)\n",
    "    ),\n",
    "    torch.tensor(data_df_train[\"enc_label_id\"].to_numpy()),\n",
    "    torch.tensor(data_df_train[\"enc_task_id\"].to_numpy()))\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(\n",
    "        np.array(data_df_test[\"mat\"].tolist()).astype(np.float32)\n",
    "    ),\n",
    "    torch.tensor(data_df_test[\"enc_label_id\"].to_numpy()),\n",
    "    torch.tensor(data_df_test[\"enc_task_id\"].to_numpy()))\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         initializing model\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = MRIVisionTransformers(\n",
    "        # output_size_tasks = config[\"d_model_task_output\"],\n",
    "        output_size_tasks = 9,\n",
    "        output_size_subjects = NUM_SUBJECTS,\n",
    "        input_size = config[\"d_model_input\"],\n",
    "        num_heads = config[\"num_heads\"],\n",
    "        dropout = config[\"dropout\"],\n",
    "        attention_dropout = config[\"attention_dropout\"]\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 400, 400)\n",
    "y = model(x)\n",
    "\n",
    "# x_si, x_td, attn_weights\n",
    "print(y[0].size())\n",
    "print(y[1].size())\n",
    "print(y[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 - loss_total: 16.9849 - acc: 0.0000 - val-loss_total: 39.3477 - val-acc: 0.0000 (11.62s/epoch)\n",
      "Epoch: 2/100 - loss_total: 19.6054 - acc: 0.0000 - val-loss_total: 10.5227 - val-acc: 0.0000 (11.09s/epoch)\n",
      "Epoch: 3/100 - loss_total: 7.4923 - acc: 0.0000 - val-loss_total: 6.6521 - val-acc: 0.0000 (10.83s/epoch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed\\notebooks\\run.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cyril/Desktop/Code/MIPLab-TeamCEE-DeepLearningforBiomed/notebooks/run.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# change to cuda\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cyril/Desktop/Code/MIPLab-TeamCEE-DeepLearningforBiomed/notebooks/run.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Cyril/Desktop/Code/MIPLab-TeamCEE-DeepLearningforBiomed/notebooks/run.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m training_loop(config[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], model, train_loader, test_loader, criterion, optimizer, device, config)\n",
      "File \u001b[1;32mc:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed\\notebooks\\../code\\training.py:93\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(epochs, model, train_loader, valid_loader, criterion, optimizer, device, config)\u001b[0m\n\u001b[0;32m     90\u001b[0m     loss_td \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_td_c\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     91\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_loss_c\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 93\u001b[0m     total_loss_c\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     94\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     96\u001b[0m train_loss_total \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\Cyril\\anaconda3\\envs\\DLbiomed\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Cyril\\anaconda3\\envs\\DLbiomed\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         training\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "# change to cuda\n",
    "device = \"cpu\"\n",
    "training_loop(config[\"epochs\"], model, train_loader, test_loader, criterion, optimizer, device, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2af70ddca1e214ae879d4eaa8be4e90c6947a1c72d95a69bb7122dd7b7c88083"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
