{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: C:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed\\DATA\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         imports\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from training import *\n",
    "from models import *\n",
    "from utils import * \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "## Data path ##\n",
    "DATA_PATH = (Path.cwd().parent / \"DATA\").resolve() # TODO : adapt to server\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "DATA_PATH = str(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         hyperparameters\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "config = {\n",
    "    # general\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "\n",
    "    # model\n",
    "    \"d_model_input\": 400,\n",
    "    \"d_model_intermediate\": 512,\n",
    "    \"d_model_task_output\": 8,\n",
    "    \"d_model_fingerprint_output\": None, # needs to be determined from data\n",
    "    \"dropout\" : 0.1,\n",
    "    \"attention_dropout\" : 0.1,\n",
    "    \"num_heads\": 4,\n",
    "    \"num_layers\": 0, # TBA?\n",
    "\n",
    "    # optimizer\n",
    "    \"lambda_si\": 0.5,\n",
    "    \"lambda_td\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         subject ID list\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "IDs = [100307,  117122,  131722,  153025,  211720,\n",
    "100408,  118528,  133019,  154734,  212318,      \n",
    "101107,  118730,  133928,  156637,  214423,        \n",
    "101309,  118932,  135225,  159340,  221319,       \n",
    "101915,  120111,  135932,  160123,  239944 ,      \n",
    "103111,  122317,  136833,  161731,  245333,        \n",
    "103414,  122620,  138534,  162733,  280739,        \n",
    "103818, 123117,  139637,  163129,  298051,        \n",
    "105014,  123925,  140925,  176542,  366446,        \n",
    "105115,  124422,  144832,  178950,  397760,        \n",
    "106016,  125525,  146432,  188347,  414229,        \n",
    "108828,  126325,  147737,  189450,  499566,\n",
    "110411,  127630,  148335,  190031,  654754,\n",
    "111312,  127933,  148840,  192540,  672756,\n",
    "111716,  128127,  149337,  196750,  751348,\n",
    "113619,  128632,  149539,  198451,  756055,\n",
    "113922,  129028,  149741,  199655,  792564,\n",
    "114419,  130013,  151223,  201111,  856766,\n",
    "115320,  130316,  151526,  208226,  857263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>mat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.21854491103466994, 0.07509374392964863, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST2</td>\n",
       "      <td>[[0.2509722712619662, 0.06429771271159306, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100307</td>\n",
       "      <td>EMOTION</td>\n",
       "      <td>[[0.27626702525883573, 0.03827488524289221, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100307</td>\n",
       "      <td>GAMBLING</td>\n",
       "      <td>[[0.2356709594115424, 0.03883497545044236, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100307</td>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>[[0.2317390561241142, 0.06537822245634475, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100307</td>\n",
       "      <td>MOTOR</td>\n",
       "      <td>[[0.2141270371266362, 0.040754342863046, 0.084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100307</td>\n",
       "      <td>RELATIONAL</td>\n",
       "      <td>[[0.2709434948110919, 0.08915439190003989, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100307</td>\n",
       "      <td>SOCIAL</td>\n",
       "      <td>[[0.27075755129825896, 0.07942572217389814, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100307</td>\n",
       "      <td>WM</td>\n",
       "      <td>[[0.28122430896568573, 0.12358947079320645, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100408</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.31926332845816463, 0.18973934066088882, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id     task_id                                                mat\n",
       "0     100307       REST1  [[0.21854491103466994, 0.07509374392964863, 0....\n",
       "1     100307       REST2  [[0.2509722712619662, 0.06429771271159306, 0.1...\n",
       "2     100307     EMOTION  [[0.27626702525883573, 0.03827488524289221, 0....\n",
       "3     100307    GAMBLING  [[0.2356709594115424, 0.03883497545044236, 0.1...\n",
       "4     100307    LANGUAGE  [[0.2317390561241142, 0.06537822245634475, 0.0...\n",
       "5     100307       MOTOR  [[0.2141270371266362, 0.040754342863046, 0.084...\n",
       "6     100307  RELATIONAL  [[0.2709434948110919, 0.08915439190003989, 0.1...\n",
       "7     100307      SOCIAL  [[0.27075755129825896, 0.07942572217389814, 0....\n",
       "8     100307          WM  [[0.28122430896568573, 0.12358947079320645, 0....\n",
       "9     100408       REST1  [[0.31926332845816463, 0.18973934066088882, 0...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         joining train and test dataframes from all subjects\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# data_dict_train, data_dict_test = get_dict_raw_data(DATA_PATH, IDs[0:3])\n",
    "data_df_train, data_df_test = get_df_raw_data(DATA_PATH, [IDs[0], IDs[5], IDs[10]])\n",
    "display(data_df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 3\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJECTS = len(data_df_train[\"subject_id\"].unique())\n",
    "print(f\"Number of subjects: {NUM_SUBJECTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         label encoding\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# one hot encoding\n",
    "\n",
    "# enc_labels = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc_tasks = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# enc_labels.fit(data_dict_train[\"subject_id\"].to_numpy().reshape(-1, 1))\n",
    "# enc_tasks.fit(data_dict_train[\"task_id\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# enc_train_label_encodings = enc_labels.transform(data_dict_train[\"subject_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "# enc_train_task_encodings = enc_tasks.transform(data_dict_train[\"task_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# enc_test_label_encodings = enc_labels.transform(data_dict_test[\"subject_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "# enc_test_task_encodings = enc_tasks.transform(data_dict_test[\"task_id\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# data_dict_train[\"enc_label_id\"] = enc_train_label_encodings.tolist()\n",
    "# data_dict_train[\"enc_task_id\"] = enc_train_task_encodings.tolist()\n",
    "\n",
    "# data_dict_test[\"enc_label_id\"] = enc_test_label_encodings.tolist()\n",
    "# data_dict_test[\"enc_task_id\"] = enc_test_task_encodings.tolist()\n",
    "\n",
    "# label encoding\n",
    "enc_labels = LabelEncoder()\n",
    "enc_tasks = LabelEncoder()\n",
    "\n",
    "enc_labels.fit(data_df_train[\"subject_id\"].tolist())\n",
    "enc_tasks.fit(data_df_train[\"task_id\"].tolist())\n",
    "\n",
    "enc_train_label_encodings = enc_labels.transform(data_df_train[\"subject_id\"].tolist())\n",
    "enc_train_task_encodings = enc_tasks.transform(data_df_train[\"task_id\"].tolist())\n",
    "\n",
    "enc_test_label_encodings = enc_labels.transform(data_df_test[\"subject_id\"].tolist())\n",
    "enc_test_task_encodings = enc_tasks.transform(data_df_test[\"task_id\"].tolist())\n",
    "\n",
    "data_df_train[\"enc_label_id\"] = enc_train_label_encodings\n",
    "data_df_train[\"enc_task_id\"] = enc_train_task_encodings\n",
    "data_df_test[\"enc_label_id\"] = enc_test_label_encodings\n",
    "data_df_test[\"enc_task_id\"] = enc_test_task_encodings\n",
    "\n",
    "#enc.inverse_transform() to reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>mat</th>\n",
       "      <th>enc_label_id</th>\n",
       "      <th>enc_task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.21854491103466994, 0.07509374392964863, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100307</td>\n",
       "      <td>REST2</td>\n",
       "      <td>[[0.2509722712619662, 0.06429771271159306, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100307</td>\n",
       "      <td>EMOTION</td>\n",
       "      <td>[[0.27626702525883573, 0.03827488524289221, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100307</td>\n",
       "      <td>GAMBLING</td>\n",
       "      <td>[[0.2356709594115424, 0.03883497545044236, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100307</td>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>[[0.2317390561241142, 0.06537822245634475, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100307</td>\n",
       "      <td>MOTOR</td>\n",
       "      <td>[[0.2141270371266362, 0.040754342863046, 0.084...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100307</td>\n",
       "      <td>RELATIONAL</td>\n",
       "      <td>[[0.2709434948110919, 0.08915439190003989, 0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100307</td>\n",
       "      <td>SOCIAL</td>\n",
       "      <td>[[0.27075755129825896, 0.07942572217389814, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100307</td>\n",
       "      <td>WM</td>\n",
       "      <td>[[0.28122430896568573, 0.12358947079320645, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100408</td>\n",
       "      <td>REST1</td>\n",
       "      <td>[[0.31926332845816463, 0.18973934066088882, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id     task_id                                                mat  \\\n",
       "0     100307       REST1  [[0.21854491103466994, 0.07509374392964863, 0....   \n",
       "1     100307       REST2  [[0.2509722712619662, 0.06429771271159306, 0.1...   \n",
       "2     100307     EMOTION  [[0.27626702525883573, 0.03827488524289221, 0....   \n",
       "3     100307    GAMBLING  [[0.2356709594115424, 0.03883497545044236, 0.1...   \n",
       "4     100307    LANGUAGE  [[0.2317390561241142, 0.06537822245634475, 0.0...   \n",
       "5     100307       MOTOR  [[0.2141270371266362, 0.040754342863046, 0.084...   \n",
       "6     100307  RELATIONAL  [[0.2709434948110919, 0.08915439190003989, 0.1...   \n",
       "7     100307      SOCIAL  [[0.27075755129825896, 0.07942572217389814, 0....   \n",
       "8     100307          WM  [[0.28122430896568573, 0.12358947079320645, 0....   \n",
       "9     100408       REST1  [[0.31926332845816463, 0.18973934066088882, 0....   \n",
       "\n",
       "   enc_label_id  enc_task_id  \n",
       "0             0            5  \n",
       "1             0            6  \n",
       "2             0            0  \n",
       "3             0            1  \n",
       "4             0            2  \n",
       "5             0            3  \n",
       "6             0            4  \n",
       "7             0            7  \n",
       "8             0            8  \n",
       "9             1            5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         initializing dataloader objects\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(\n",
    "        np.array(data_df_train[\"mat\"].tolist()).astype(np.float32)\n",
    "    ),\n",
    "    torch.tensor(data_df_train[\"enc_label_id\"].to_numpy()),\n",
    "    torch.tensor(data_df_train[\"enc_task_id\"].to_numpy()))\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(\n",
    "        np.array(data_df_test[\"mat\"].tolist()).astype(np.float32)\n",
    "    ),\n",
    "    torch.tensor(data_df_test[\"enc_label_id\"].to_numpy()),\n",
    "    torch.tensor(data_df_test[\"enc_task_id\"].to_numpy()))\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         initializing model\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = MRIVisionTransformers(\n",
    "        # output_size_tasks = config[\"d_model_task_output\"],\n",
    "        output_size_tasks = 9,\n",
    "        output_size_subjects = NUM_SUBJECTS,\n",
    "        input_size = config[\"d_model_input\"],\n",
    "        num_heads = config[\"num_heads\"],\n",
    "        dropout = config[\"dropout\"],\n",
    "        attention_dropout = config[\"attention_dropout\"]\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 400, 400)\n",
    "y = model(x)\n",
    "\n",
    "# x_si, x_td, attn_weights\n",
    "print(y[0].size())\n",
    "print(y[1].size())\n",
    "print(y[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mc-achard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=c:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed, universal_newlines=False, shell=None, istream=<valid stream>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848572731d4c4678978c7f82b5df3c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Cyril\\Desktop\\Code\\MIPLab-TeamCEE-DeepLearningforBiomed\\notebooks\\wandb\\run-20231124_105641-ft6pqbit</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/c-achard/DLB-Project/runs/ft6pqbit' target=\"_blank\">generous-oath-2</a></strong> to <a href='https://wandb.ai/c-achard/DLB-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/c-achard/DLB-Project' target=\"_blank\">https://wandb.ai/c-achard/DLB-Project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/c-achard/DLB-Project/runs/ft6pqbit' target=\"_blank\">https://wandb.ai/c-achard/DLB-Project/runs/ft6pqbit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 34.34313121863774\n",
      "DEBUG:training:TD loss : 35.08243611880711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 - loss_total: 34.7128- Acc: SI 0.3333 / TD 0.0000- val-loss_total: 30.0611 - val-acc: SI 0.6667 TD 0.0000(15.15s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 20.942123906952993\n",
      "DEBUG:training:TD loss : 26.07610947745187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 - loss_total: 23.5091- Acc: SI 0.3333 / TD 0.0000- val-loss_total: 11.8013 - val-acc: SI 1.0000 TD 0.0000(14.33s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 5.507892233984811\n",
      "DEBUG:training:TD loss : 9.467350687299456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100 - loss_total: 7.4876- Acc: SI 0.6667 / TD 0.0000- val-loss_total: 8.1839 - val-acc: SI 0.0000 TD 0.0000(13.15s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 4.738003496612821\n",
      "DEBUG:training:TD loss : 7.887131043842861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100 - loss_total: 6.3126- Acc: SI 0.3333 / TD 0.3333- val-loss_total: 6.1790 - val-acc: SI 0.3333 TD 0.0000(13.29s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.4535096193264638\n",
      "DEBUG:training:TD loss : 3.872344970703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100 - loss_total: 2.1629- Acc: SI 0.6667 / TD 0.0000- val-loss_total: 4.1052 - val-acc: SI 0.0000 TD 0.0000(14.34s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.6509033528023532\n",
      "DEBUG:training:TD loss : 2.786150710923331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 - loss_total: 1.7185- Acc: SI 1.0000 / TD 0.3333- val-loss_total: 3.1323 - val-acc: SI 0.0000 TD 0.0000(16.15s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.5169490594416857\n",
      "DEBUG:training:TD loss : 1.962415188550949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100 - loss_total: 1.2397- Acc: SI 1.0000 / TD 0.6667- val-loss_total: 3.9482 - val-acc: SI 0.0000 TD 0.0000(14.77s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.5420748053916863\n",
      "DEBUG:training:TD loss : 0.8059181187834058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100 - loss_total: 0.6740- Acc: SI 1.0000 / TD 1.0000- val-loss_total: 3.6267 - val-acc: SI 0.0000 TD 0.3333(13.30s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.23554155443395888\n",
      "DEBUG:training:TD loss : 0.6389163125838552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100 - loss_total: 0.4372- Acc: SI 1.0000 / TD 0.6667- val-loss_total: 3.6155 - val-acc: SI 0.0000 TD 0.0000(13.28s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.23226335870900325\n",
      "DEBUG:training:TD loss : 0.6496180616585272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100 - loss_total: 0.4409- Acc: SI 0.6667 / TD 1.0000- val-loss_total: 2.9531 - val-acc: SI 0.3333 TD 0.3333(18.78s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.20370155388289796\n",
      "DEBUG:training:TD loss : 0.35363257250615526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 - loss_total: 0.2787- Acc: SI 0.6667 / TD 1.0000- val-loss_total: 3.5183 - val-acc: SI 0.0000 TD 0.0000(16.08s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.09563975045706943\n",
      "DEBUG:training:TD loss : 0.21655552142432757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100 - loss_total: 0.1561- Acc: SI 1.0000 / TD 1.0000- val-loss_total: 2.9584 - val-acc: SI 0.3333 TD 0.0000(13.72s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.06322576471835159\n",
      "DEBUG:training:TD loss : 0.15258048541311706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 - loss_total: 0.1079- Acc: SI 1.0000 / TD 1.0000- val-loss_total: 2.9895 - val-acc: SI 0.3333 TD 0.0000(16.18s/epoch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:training:SI loss : 0.04730315689130293\n",
      "DEBUG:training:TD loss : 0.2575010082551411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100 - loss_total: 0.1524- Acc: SI 1.0000 / TD 1.0000- val-loss_total: 2.9290 - val-acc: SI 0.3333 TD 0.0000(15.98s/epoch)\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "#         training\n",
    "###-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "# change to cuda\n",
    "device = \"cpu\"\n",
    "training_loop(config[\"epochs\"], model, train_loader, test_loader, criterion, optimizer, device, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2af70ddca1e214ae879d4eaa8be4e90c6947a1c72d95a69bb7122dd7b7c88083"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
